{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnWickKeanue/psa-website-bypass/blob/main/PSA_bypass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading Cloud-Scraper...\")\n",
        "!pip install cloudscraper\n",
        "print(\"Importing Files!\")\n",
        "import time\n",
        "import requests \n",
        "import re\n",
        "import cloudscraper \n",
        "import concurrent.futures\n",
        "from bs4  import BeautifulSoup\n",
        "\n",
        "psa_url= \"\" #@param {type:\"string\"}\n",
        "\n",
        "print(\"You Have Entered:\")\n",
        "print(\"Checking Link...\")\n",
        "def psa_bypasser(psa_url):\n",
        " client = cloudscraper.create_scraper(allow_brotli=False)\n",
        " r = client.get(psa_url)\n",
        " soup = BeautifulSoup(r.text, \"html.parser\").find_all(class_=\"dropshadowboxes-drop-shadow dropshadowboxes-rounded-corners dropshadowboxes-inside-and-outside-shadow dropshadowboxes-lifted-both dropshadowboxes-effect-default\")\n",
        "    \n",
        " with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "  for link in soup:\n",
        "   try:\n",
        "    exit_gate = link.a.get(\"href\")\n",
        "    executor.submit(try2link_scrape, exit_gate)\n",
        "   except: pass\n",
        "\n",
        "def try2link_scrape(url):\n",
        " client = cloudscraper.create_scraper(allow_brotli=False) \n",
        " h = {\n",
        " 'upgrade-insecure-requests': '1', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36',\n",
        " }\n",
        " res = client.get(url, cookies={}, headers=h)\n",
        " url = 'https://try2link.com/'+re.findall('try2link\\.com\\/(.*?) ', res.text)[0]\n",
        " print(try2link_bypass(url))\n",
        "\n",
        "def try2link_bypass(url):\n",
        " client = cloudscraper.create_scraper(allow_brotli=False)\n",
        "    \n",
        " url = url[:-1] if url[-1] == '/' else url\n",
        "    \n",
        " params = (('d', int(time.time()) + (60 * 4)),)\n",
        " r = client.get(url, params=params, headers= {'Referer': 'https://newforex.online/'})\n",
        "    \n",
        " soup = BeautifulSoup(r.text, 'html.parser')\n",
        " inputs = soup.find(id=\"go-link\").find_all(name=\"input\")\n",
        " data = { input.get('name'): input.get('value') for input in inputs } \n",
        " time.sleep(7)\n",
        "    \n",
        " headers = {'Host': 'try2link.com', 'X-Requested-With': 'XMLHttpRequest', 'Origin': 'https://try2link.com', 'Referer': url}\n",
        "    \n",
        " bypassed_url = client.post('https://try2link.com/links/go', headers=headers,data=data)\n",
        " return bypassed_url.json()[\"url\"]\n",
        "  \n",
        "\n",
        "    \n",
        "print(psa_bypasser(psa_url))"
      ],
      "metadata": {
        "id": "7KCgN02c6Ubp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}